{
  "src/llama-sampling.cpp": {
    "status": "modified",
    "patch": "@@ -798,7 +798,7 @@ static void llama_sampler_min_p_apply(struct llama_sampler * smpl, llama_token_d\n         }\n \n         // if we have enough values the operation was a success\n-        if (filtered_tokens.size() >= ctx->min_keep) {\n+        if (!filtered_tokens.empty() && filtered_tokens.size() >= ctx->min_keep) {\n             memcpy(cur_p->data, filtered_tokens.data(), filtered_tokens.size()*sizeof(llama_token_data));\n             cur_p->size = filtered_tokens.size();\n             min_p_applied = true;\n@@ -909,7 +909,7 @@ static void llama_sampler_typical_apply(struct llama_sampler * smpl, llama_token\n         cum_sum += cur_p->data[idx].p;\n \n         // Check if the running sum is greater than typical or if we have kept at least min_keep tokens\n-        if (cum_sum > ctx->p && i >= ctx->min_keep - 1) {\n+        if (cum_sum > ctx->p && (ctx->min_keep == 0 || i >= ctx->min_keep - 1)) {\n             last_idx = i + 1;\n             break;\n         }",
    "additions": 2,
    "deletions": 2,
    "changes": 4,
    "language": "cpp",
    "imports": [
      "#include \"llama-sampling.h\"",
      "#include \"llama-impl.h\"",
      "#include \"llama-vocab.h\"",
      "#include \"llama-grammar.h\"",
      "#include <algorithm>",
      "#include <cassert>",
      "#include <cfloat>",
      "#include <chrono>",
      "#include <cmath>",
      "#include <cstdlib>"
    ],
    "full_content": "#include \"llama-sampling.h\"\n\n#include \"llama-impl.h\"\n#include \"llama-vocab.h\"\n#include \"llama-grammar.h\"\n\n#include <algorithm>\n#include <cassert>\n#include <cfloat>\n#include <chrono>\n#include <cmath>\n#include <cstdlib>\n#include <cstring>\n#include <ctime>\n#include <numeric>\n#include <random>\n#include <unordered_map>\n#include <stdexcept>\n\n// the ring buffer works similarly to std::deque, but with a fixed capacity\ntemplate<typename T>\nstruct ring_buffer {\n    ring_buffer(size_t cap) : capacity(cap), data(cap) {}\n\n    T & front() {\n        if (sz == 0) {\n            throw std::runtime_error(\"ring buffer is empty\");\n        }\n        return data[first];\n    }\n\n    const T & front() const {\n        if (sz == 0) {\n            throw std::runtime_error(\"ring buffer is empty\");\n        }\n        return data[first];\n    }\n\n    T & back() {\n        if (sz == 0) {\n            throw std::runtime_error(\"ring buffer is empty\");\n        }\n        return data[pos];\n    }\n\n    const T & back() const {\n        if (sz == 0) {\n            throw std::runtime_error(\"ring buffer is empty\");\n        }\n        return data[pos];\n    }\n\n    void push_back(const T & value) {\n        if (capacity == 0) {\n            throw std::runtime_error(\"ring buffer: capacity is zero\");\n        }\n\n        if (sz == capacity) {\n            // advance the start when buffer is full\n            first = (first + 1) % capacity;\n        } else {\n            sz++;\n        }\n        data[pos] = value;\n        pos = (pos + 1) % capacity;\n    }\n\n    T pop_front() {\n        if (sz == 0) {\n            throw std::runtime_error(\"ring buffer is empty\");\n        }\n        T value = data[first];\n        first = (first + 1) % capacity;\n        sz--;\n        return value;\n    }\n\n    //T & operator[](size_t i) {\n    //    if (i >= sz) {\n    //        throw std::runtime_error(\"ring buffer: index out of bounds\");\n    //    }\n    //    return data[(first + i) % capacity];\n    //}\n\n    //const T & at(size_t i) const {\n    //    if (i ",
    "raw_url": "https://github.com/ggml-org/llama.cpp/raw/9065ca71a29009b7a090879e6dbe4117c9632862/src%2Fllama-sampling.cpp",
    "is_test_file": false
  },
  "tests/test-sampling.cpp": {
    "status": "modified",
    "patch": "@@ -98,7 +98,7 @@ static void test_top_p(const std::vector<float> & probs, const std::vector<float\n     sampler_tester tester(probs, probs_expected);\n \n     DUMP(&tester.cur_p);\n-    tester.apply(llama_sampler_init_top_p(p, 1));\n+    tester.apply(llama_sampler_init_top_p(p, 0));\n     tester.apply(llama_sampler_init_dist (0));\n     DUMP(&tester.cur_p);\n \n@@ -109,7 +109,7 @@ static void test_min_p(const std::vector<float> & probs, const std::vector<float\n     sampler_tester tester(probs, probs_expected);\n \n     DUMP(&tester.cur_p);\n-    tester.apply(llama_sampler_init_min_p(p, 1));\n+    tester.apply(llama_sampler_init_min_p(p, 0));\n     tester.apply(llama_sampler_init_dist (0));\n     DUMP(&tester.cur_p);\n \n@@ -130,7 +130,7 @@ static void test_typical(const std::vector<float> & probs, const std::vector<flo\n     sampler_tester tester(probs, probs_expected);\n \n     DUMP(&tester.cur_p);\n-    tester.apply(llama_sampler_init_typical(p, 1));\n+    tester.apply(llama_sampler_init_typical(p, 0));\n     DUMP(&tester.cur_p);\n \n     tester.check();\n@@ -332,6 +332,7 @@ int main(void) {\n     test_min_p({0.1f, 0.2f, 0.3f, 0.4f}, {0.4f/0.7f, 0.3f/0.7f},                       0.74f);\n     test_min_p({0.1f, 0.2f, 0.3f, 0.4f}, {0.4f/0.4f},                                  0.76f);\n     test_min_p({0.1f, 0.2f, 0.3f, 0.4f}, {0.4f/0.4f},                                  1.00f);\n+    test_min_p({0.1f, 0.2f, 0.3f, 0.4f}, {0.4f/0.4f},                                  1.05f);\n \n     printf(\"XTC should:\\n\");\n     test_xtc({0.4f, 0.3f, 0.2f, 0.1f},   {0.1f},                                0.99f, 0.09f);\n@@ -341,8 +342,8 @@ int main(void) {\n     printf(\"XTC should not:\\n\");\n     test_xtc({0.4f, 0.3f, 0.2f, 0.1f},   {0.4f, 0.3f, 0.2f, 0.1f},              0.99f, 0.39f);\n \n-    test_typical({0.97f, 0.01f, 0.01f, 0.01f}, {0.97f}, 0.5f);\n-    test_typical({0.4f, 0.2f, 0.2f, 0.2f}, {0.2f, 0.2f, 0.2f}, 0.5f);\n+    test_typical({0.97f, 0.01f, 0.01f, 0.01f}, {0.97f},            0.5f);\n+    test_typical({0.4f, 0.2f, 0.2f, 0.2f},     {0.2f, 0.2f, 0.2f}, 0.5f);\n \n     test_penalties({0.2f, 0.2f, 0.2f, 0.2f, 0.2f}, {0}, {0.25f, 0.25f, 0.25f, 0.25f, 0},   50.0f, 0.0f, 0.0f);\n     test_penalties({0.2f, 0.2f, 0.2f, 0.2f, 0.2f}, {0, 1, 2}, {0.5f, 0.5f, 0, 0, 0},       50.0f, 0.0f, 0.0f);",
    "additions": 6,
    "deletions": 5,
    "changes": 11,
    "language": "cpp",
    "imports": [
      "#include \"ggml.h\"",
      "#include \"llama.h\"",
      "#include <algorithm>",
      "#include <cmath>",
      "#include <string>",
      "#include <vector>"
    ],
    "full_content": "#include \"ggml.h\"\n#include \"llama.h\"\n\n#ifdef NDEBUG\n#undef NDEBUG\n#endif\n\n#include <algorithm>\n#include <cmath>\n#include <string>\n#include <vector>\n\nextern struct llama_sampler * llama_sampler_init_dry_testing(int32_t context_size, float dry_multiplier, float dry_base, int32_t dry_allowed_length, int32_t dry_penalty_last_n, const std::vector<std::vector<llama_token>>& seq_breakers);\n\nstatic void dump(const llama_token_data_array * cur_p) {\n    for (size_t i = 0; i < cur_p->size; i++) {\n        printf(\"%d: %f (%f)\\n\", cur_p->data[i].id, cur_p->data[i].p, cur_p->data[i].logit);\n    }\n}\n\n#define DUMP(__cur_p) do { printf(\"%s:%d (%s)\\n\", __FILE__, __LINE__, __func__); dump((__cur_p)); printf(\"-\\n\"); } while(0)\n\nstruct sampler_tester {\n    sampler_tester(size_t n_vocab) {\n        cur.reserve(n_vocab);\n        for (llama_token token_id = 0; token_id < (llama_token)n_vocab; token_id++) {\n            const float logit = logf(token_id);\n            cur.emplace_back(llama_token_data{token_id, logit, 0.0f});\n        }\n\n        cur_p = llama_token_data_array { cur.data(), cur.size(), -1, false };\n    }\n\n    sampler_tester(const std::vector<float> & probs, const std::vector<float> & probs_expected) : probs_expected(probs_expected) {\n        cur.reserve(probs.size());\n        for (llama_token token_id = 0; token_id < (llama_token)probs.size(); token_id++) {\n            const float logit = logf(probs[token_id]);\n            cur.emplace_back(llama_token_data{token_id, logit, probs[token_id]});\n        }\n\n        cur_p = llama_token_data_array { cur.data(), cur.size(), -1, false };\n    }\n\n    void apply(llama_sampler * sampler) {\n        llama_sampler_apply(sampler, &cur_p);\n        llama_sampler_free(sampler);\n    }\n\n    void check() {\n        GGML_ASSERT(cur_p.size == probs_expected.size());\n        for (size_t i = 0; i < cur_p.size; i++) {\n            GGML_ASSERT(fabs(cur_p.data[i].p - probs_expected[i]) < 1e-5);\n        }\n    }\n\n    llama_token_data_array cur_p;\n\nprivate:\n    co",
    "raw_url": "https://github.com/ggml-org/llama.cpp/raw/9065ca71a29009b7a090879e6dbe4117c9632862/tests%2Ftest-sampling.cpp",
    "is_test_file": true
  }
}