{
  "ggml/src/ggml-vulkan/ggml-vulkan.cpp": "@@ -343,6 +343,9 @@ enum vk_conv_shapes {\n     CONV_SHAPE_COUNT,\n };\n \n+static constexpr uint32_t num_argsort_pipelines = 11;\n+static constexpr uint32_t max_argsort_cols = 1 << (num_argsort_pipelines-1);\n+\n struct vk_device_struct {\n     std::recursive_mutex mutex;\n \n@@ -499,7 +502,7 @@ struct vk_device_struct {\n     vk_pipeline pipeline_rope_neox_f32, pipeline_rope_neox_f16;\n     vk_pipeline pipeline_rope_multi_f32, pipeline_rope_multi_f16;\n     vk_pipeline pipeline_rope_vision_f32, pipeline_rope_vision_f16;\n-    vk_pipeline pipeline_argsort_f32;\n+    vk_pipeline pipeline_argsort_f32[num_argsort_pipelines];\n     vk_pipeline pipeline_sum_rows_f32;\n     vk_pipeline pipeline_argmax_f32;\n     vk_pipeline pipeline_count_equal_i32;\n@@ -856,7 +859,6 @@ struct vk_op_soft_max_push_constants {\n \n struct vk_op_argsort_push_constants {\n     uint32_t ncols;\n-    uint32_t ncols_pad;\n     int32_t order;\n };\n \n@@ -3103,7 +3105,9 @@ static void ggml_vk_load_shaders(vk_device& device) {\n         ggml_vk_create_pipeline(device, device->pipeline_rope_vision_f16, \"rope_vision_f16\", rope_vision_f16_len, rope_vision_f16_data, \"main\", 4, sizeof(vk_op_rope_push_constants), {1, 512, 1}, {}, 1);\n     }\n \n-    ggml_vk_create_pipeline(device, device->pipeline_argsort_f32, \"argsort_f32\", argsort_f32_len, argsort_f32_data, \"main\", 2, sizeof(vk_op_argsort_push_constants), {1024, 1, 1}, {}, 1);\n+    for (uint32_t i = 0; i < num_argsort_pipelines; ++i) {\n+        ggml_vk_create_pipeline(device, device->pipeline_argsort_f32[i], \"argsort_f32_\"+std::to_string(i), argsort_f32_len, argsort_f32_data, \"main\", 2, sizeof(vk_op_argsort_push_constants), {1u<<i, 1, 1}, {1u<<i, i}, 1, true);\n+    }\n \n     ggml_vk_create_pipeline(device, device->pipeline_argmax_f32, \"argmax_f32\", argmax_f32_len, argmax_f32_data, \"main\", 2, sizeof(vk_op_push_constants), {1, 1, 1}, { device->subgroup_size }, 1);\n \n@@ -7145,7 +7149,8 @@ static vk_pipeline ggml_vk_op_get_pipeline(ggml_backend_vk_context * ctx, const\n         }\n     case GGML_OP_ARGSORT:\n         if (src0->type == GGML_TYPE_F32 && dst->type == GGML_TYPE_I32) {\n-            return ctx->device->pipeline_argsort_f32;\n+            uint32_t idx = (uint32_t)ceilf(log2f(float(dst->ne[0])));\n+            return ctx->device->pipeline_argsort_f32[idx];\n         }\n         return nullptr;\n     case GGML_OP_SUM:\n@@ -8369,16 +8374,8 @@ static void ggml_vk_argsort(ggml_backend_vk_context * ctx, vk_context& subctx, c\n \n     uint32_t ncols = src0->ne[0];\n \n-    uint32_t ncols_pad = 1;\n-    while (ncols_pad < ncols) {\n-        ncols_pad *= 2;\n-    }\n-\n-    GGML_ASSERT(ncols_pad <= 1024);\n-\n     ggml_vk_op_f32<vk_op_argsort_push_constants>(ctx, subctx, src0, nullptr, nullptr, dst, GGML_OP_ARGSORT, {\n         ncols,\n-        ncols_pad,\n         op_params[0],\n     }, dryrun);\n }\n@@ -11189,6 +11186,8 @@ static bool ggml_backend_vk_device_supports_op(ggml_backend_dev_t dev, const ggm\n         case GGML_OP_OPT_STEP_ADAMW:\n         case GGML_OP_OPT_STEP_SGD:\n             return op->src[0]->type == GGML_TYPE_F32;\n+        case GGML_OP_ARGSORT:\n+            return op->ne[0] <= max_argsort_cols;\n         case GGML_OP_UPSCALE:\n         case GGML_OP_ACC:\n         case GGML_OP_CONCAT:\n@@ -11198,7 +11197,6 @@ static bool ggml_backend_vk_device_supports_op(ggml_backend_dev_t dev, const ggm\n         case GGML_OP_DIAG_MASK_INF:\n         case GGML_OP_SOFT_MAX:\n         case GGML_OP_SOFT_MAX_BACK:\n-        case GGML_OP_ARGSORT:\n         case GGML_OP_SUM:\n         case GGML_OP_SUM_ROWS:\n         case GGML_OP_ARGMAX:",
  "ggml/src/ggml-vulkan/vulkan-shaders/argsort.comp": "@@ -1,69 +1,79 @@\n #version 450\n+#extension GL_EXT_control_flow_attributes : enable\n \n #include \"types.comp\"\n \n-#define BLOCK_SIZE 1024\n+layout(constant_id = 0) const int BLOCK_SIZE = 1024;\n+layout(constant_id = 1) const int BLOCK_SIZE_LOG2 = 10;\n #define ASC 0\n \n-layout(local_size_x = BLOCK_SIZE, local_size_y = 1, local_size_z = 1) in;\n+layout(local_size_x_id = 0, local_size_y = 1, local_size_z = 1) in;\n \n layout (binding = 0) readonly buffer A {A_TYPE data_a[];};\n layout (binding = 1)          buffer D {int data_d[];};\n \n layout (push_constant) uniform parameter {\n     uint ncols;\n-    uint ncols_pad;\n     uint order;\n } p;\n \n shared int dst_row[BLOCK_SIZE];\n+shared A_TYPE a_sh[BLOCK_SIZE];\n \n void swap(uint idx0, uint idx1) {\n     int tmp = dst_row[idx0];\n     dst_row[idx0] = dst_row[idx1];\n     dst_row[idx1] = tmp;\n }\n \n-void main() {\n+void argsort(bool needs_bounds_check) {\n     // bitonic sort\n     const int col = int(gl_LocalInvocationID.x);\n     const uint row = gl_WorkGroupID.y;\n \n     const uint row_offset = row * p.ncols;\n \n     // initialize indices\n-    if (col < p.ncols_pad) {\n-        dst_row[col] = col;\n-    }\n+    dst_row[col] = col;\n+    a_sh[col] = data_a[row_offset + col];\n     barrier();\n \n-    for (uint k = 2; k <= p.ncols_pad; k *= 2) {\n-        for (uint j = k / 2; j > 0; j /= 2) {\n-            const uint ixj = col ^ j;\n-            if (col < p.ncols_pad && ixj > col) {\n-                if ((col & k) == 0) {\n-                    if (dst_row[col] >= p.ncols ||\n-                        (dst_row[ixj] < p.ncols && (p.order == ASC ?\n-                            data_a[row_offset + dst_row[col]] > data_a[row_offset + dst_row[ixj]] :\n-                            data_a[row_offset + dst_row[col]] < data_a[row_offset + dst_row[ixj]]))\n-                    ) {\n-                        swap(col, ixj);\n-                    }\n-                } else {\n-                    if (dst_row[ixj] >= p.ncols ||\n-                        (dst_row[col] < p.ncols && (p.order == ASC ?\n-                            data_a[row_offset + dst_row[col]] < data_a[row_offset + dst_row[ixj]] :\n-                            data_a[row_offset + dst_row[col]] > data_a[row_offset + dst_row[ixj]]))\n-                    ) {\n-                        swap(col, ixj);\n-                    }\n-                }\n+    uint num_outer_loop_iters = BLOCK_SIZE_LOG2;\n+    [[unroll]] for (uint k = 2, outer_idx = 0; outer_idx < num_outer_loop_iters; k *= 2, outer_idx++) {\n+        uint num_inner_loop_iters = outer_idx + 1;\n+        [[unroll]] for (uint j = k / 2, inner_idx = 0; inner_idx < num_inner_loop_iters; j /= 2, inner_idx++) {\n+            const int ixj = int(col ^ j);\n+\n+            int idx_0 = (col & k) == 0 ? col : ixj;\n+            int idx_1 = (col & k) == 0 ? ixj : col;\n+\n+            int sh_idx_0 = dst_row[idx_0];\n+            int sh_idx_1 = dst_row[idx_1];\n+            bool idx_0_oob = needs_bounds_check ? sh_idx_0 >= p.ncols : false;\n+            bool idx_1_oob = needs_bounds_check ? sh_idx_1 >= p.ncols : false;\n+\n+            if ((idx_0_oob ||\n+                (!idx_1_oob && a_sh[sh_idx_0] > a_sh[sh_idx_1])) && (ixj > col)) {\n+                swap(idx_0, idx_1);\n             }\n+\n             barrier();\n         }\n     }\n \n     if (col < p.ncols) {\n-        data_d[row_offset + col] = dst_row[col];\n+        if (p.order == ASC) {\n+            data_d[row_offset + col] = dst_row[col];\n+        } else {\n+            data_d[row_offset + p.ncols - col - 1] = dst_row[col];\n+        }\n+    }\n+}\n+\n+void main() {\n+    if (p.ncols == BLOCK_SIZE) {\n+        argsort(false);\n+    } else {\n+        argsort(true);\n     }\n }",
  "tests/test-backend-ops.cpp": "@@ -6024,6 +6024,7 @@ static std::vector<std::unique_ptr<test_case>> make_test_cases_eval() {\n         test_cases.emplace_back(new test_argsort(GGML_TYPE_F32, {8, 1, 1, 1}, order));\n         test_cases.emplace_back(new test_argsort(GGML_TYPE_F32, {16, 10, 10, 10}, order));\n         test_cases.emplace_back(new test_argsort(GGML_TYPE_F32, {60, 10, 10, 10}, order)); // qwen\n+        test_cases.emplace_back(new test_argsort(GGML_TYPE_F32, {1024, 1, 1, 1}, order));\n     }\n \n     for (ggml_scale_mode mode : {GGML_SCALE_MODE_NEAREST, GGML_SCALE_MODE_BILINEAR}) {"
}