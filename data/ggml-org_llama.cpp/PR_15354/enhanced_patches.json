{
  "ggml/src/ggml-vulkan/ggml-vulkan.cpp": {
    "status": "modified",
    "patch": "@@ -343,6 +343,9 @@ enum vk_conv_shapes {\n     CONV_SHAPE_COUNT,\n };\n \n+static constexpr uint32_t num_argsort_pipelines = 11;\n+static constexpr uint32_t max_argsort_cols = 1 << (num_argsort_pipelines-1);\n+\n struct vk_device_struct {\n     std::recursive_mutex mutex;\n \n@@ -499,7 +502,7 @@ struct vk_device_struct {\n     vk_pipeline pipeline_rope_neox_f32, pipeline_rope_neox_f16;\n     vk_pipeline pipeline_rope_multi_f32, pipeline_rope_multi_f16;\n     vk_pipeline pipeline_rope_vision_f32, pipeline_rope_vision_f16;\n-    vk_pipeline pipeline_argsort_f32;\n+    vk_pipeline pipeline_argsort_f32[num_argsort_pipelines];\n     vk_pipeline pipeline_sum_rows_f32;\n     vk_pipeline pipeline_argmax_f32;\n     vk_pipeline pipeline_count_equal_i32;\n@@ -856,7 +859,6 @@ struct vk_op_soft_max_push_constants {\n \n struct vk_op_argsort_push_constants {\n     uint32_t ncols;\n-    uint32_t ncols_pad;\n     int32_t order;\n };\n \n@@ -3103,7 +3105,9 @@ static void ggml_vk_load_shaders(vk_device& device) {\n         ggml_vk_create_pipeline(device, device->pipeline_rope_vision_f16, \"rope_vision_f16\", rope_vision_f16_len, rope_vision_f16_data, \"main\", 4, sizeof(vk_op_rope_push_constants), {1, 512, 1}, {}, 1);\n     }\n \n-    ggml_vk_create_pipeline(device, device->pipeline_argsort_f32, \"argsort_f32\", argsort_f32_len, argsort_f32_data, \"main\", 2, sizeof(vk_op_argsort_push_constants), {1024, 1, 1}, {}, 1);\n+    for (uint32_t i = 0; i < num_argsort_pipelines; ++i) {\n+        ggml_vk_create_pipeline(device, device->pipeline_argsort_f32[i], \"argsort_f32_\"+std::to_string(i), argsort_f32_len, argsort_f32_data, \"main\", 2, sizeof(vk_op_argsort_push_constants), {1u<<i, 1, 1}, {1u<<i, i}, 1, true);\n+    }\n \n     ggml_vk_create_pipeline(device, device->pipeline_argmax_f32, \"argmax_f32\", argmax_f32_len, argmax_f32_data, \"main\", 2, sizeof(vk_op_push_constants), {1, 1, 1}, { device->subgroup_size }, 1);\n \n@@ -7145,7 +7149,8 @@ static vk_pipeline ggml_vk_op_get_pipeline(ggml_backend_vk_context * ctx, const\n         }\n     case GGML_OP_ARGSORT:\n         if (src0->type == GGML_TYPE_F32 && dst->type == GGML_TYPE_I32) {\n-            return ctx->device->pipeline_argsort_f32;\n+            uint32_t idx = (uint32_t)ceilf(log2f(float(dst->ne[0])));\n+            return ctx->device->pipeline_argsort_f32[idx];\n         }\n         return nullptr;\n     case GGML_OP_SUM:\n@@ -8369,16 +8374,8 @@ static void ggml_vk_argsort(ggml_backend_vk_context * ctx, vk_context& subctx, c\n \n     uint32_t ncols = src0->ne[0];\n \n-    uint32_t ncols_pad = 1;\n-    while (ncols_pad < ncols) {\n-        ncols_pad *= 2;\n-    }\n-\n-    GGML_ASSERT(ncols_pad <= 1024);\n-\n     ggml_vk_op_f32<vk_op_argsort_push_constants>(ctx, subctx, src0, nullptr, nullptr, dst, GGML_OP_ARGSORT, {\n         ncols,\n-        ncols_pad,\n         op_params[0],\n     }, dryrun);\n }\n@@ -11189,6 +11186,8 @@ static bool ggml_backend_vk_device_supports_op(ggml_backend_dev_t dev, const ggm\n         case GGML_OP_OPT_STEP_ADAMW:\n         case GGML_OP_OPT_STEP_SGD:\n             return op->src[0]->type == GGML_TYPE_F32;\n+        case GGML_OP_ARGSORT:\n+            return op->ne[0] <= max_argsort_cols;\n         case GGML_OP_UPSCALE:\n         case GGML_OP_ACC:\n         case GGML_OP_CONCAT:\n@@ -11198,7 +11197,6 @@ static bool ggml_backend_vk_device_supports_op(ggml_backend_dev_t dev, const ggm\n         case GGML_OP_DIAG_MASK_INF:\n         case GGML_OP_SOFT_MAX:\n         case GGML_OP_SOFT_MAX_BACK:\n-        case GGML_OP_ARGSORT:\n         case GGML_OP_SUM:\n         case GGML_OP_SUM_ROWS:\n         case GGML_OP_ARGMAX:",
    "additions": 11,
    "deletions": 13,
    "changes": 24,
    "language": "cpp",
    "imports": [
      "#include \"ggml-vulkan.h\"",
      "#include <vulkan/vulkan_core.h>",
      "#include <chrono>",
      "#include \"ggml-cpu.h\"",
      "#include <vulkan/vulkan.hpp>",
      "#include <algorithm>",
      "#include <cmath>",
      "#include <iomanip>",
      "#include <iostream>",
      "#include <tuple>"
    ],
    "full_content": "#include \"ggml-vulkan.h\"\n#include <vulkan/vulkan_core.h>\n#if defined(GGML_VULKAN_RUN_TESTS) || defined(GGML_VULKAN_CHECK_RESULTS)\n#include <chrono>\n#include \"ggml-cpu.h\"\n#endif\n\n#include <vulkan/vulkan.hpp>\n\n#include <algorithm>\n#include <cmath>\n#include <iomanip>\n#include <iostream>\n#include <tuple>\n#include <vector>\n#include <sstream>\n#include <utility>\n#include <memory>\n#include <limits>\n#include <map>\n#include <unordered_map>\n#include <memory>\n#include <mutex>\n#include <future>\n#include <thread>\n\n#if defined(_MSC_VER)\n# define NOMINMAX 1\n# include <windows.h>\n# define YIELD() YieldProcessor()\n#elif defined(__clang__) || defined(__GNUC__)\n# if defined(__x86_64__) ||defined(__i386__)\n#  include <immintrin.h>\n#  define YIELD() _mm_pause()\n# elif defined(__arm__) || defined(__aarch64__)\n#  if defined(__clang__)\n#   include <arm_acle.h>\n#   define YIELD() __yield()\n#  else\n#   define YIELD() asm volatile(\"yield\")\n#  endif\n# endif\n#endif\n\n#if !defined(YIELD)\n#define YIELD()\n#endif\n\n#include \"ggml-impl.h\"\n#include \"ggml-backend-impl.h\"\n\n#include \"ggml-vulkan-shaders.hpp\"\n\n// remove this once it's more widely available in the SDK\n#if !defined(VK_KHR_shader_bfloat16)\n\n#define VK_KHR_shader_bfloat16 1\n#define VK_KHR_SHADER_BFLOAT16_SPEC_VERSION                          1\n#define VK_KHR_SHADER_BFLOAT16_EXTENSION_NAME                        \"VK_KHR_shader_bfloat16\"\n#define VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SHADER_BFLOAT16_FEATURES_KHR ((VkStructureType)1000141000)\n#define VK_COMPONENT_TYPE_BFLOAT16_KHR                               ((VkComponentTypeKHR)1000141000)\n\ntypedef struct VkPhysicalDeviceShaderBfloat16FeaturesKHR {\n    VkStructureType                       sType;\n    void*                                 pNext;\n    VkBool32                              shaderBFloat16Type;\n    VkBool32                              shaderBFloat16DotProduct;\n    VkBool32                              shaderBFloat16CooperativeMatrix;\n} VkPhysicalDeviceShaderBfloat16FeaturesKHR;\n#endif\n\n#",
    "raw_url": "https://github.com/ggml-org/llama.cpp/raw/c9e4504a780b32c13a9c0fad51164bc0c27cb8c1/ggml%2Fsrc%2Fggml-vulkan%2Fggml-vulkan.cpp",
    "is_test_file": false
  },
  "ggml/src/ggml-vulkan/vulkan-shaders/argsort.comp": {
    "status": "modified",
    "patch": "@@ -1,69 +1,79 @@\n #version 450\n+#extension GL_EXT_control_flow_attributes : enable\n \n #include \"types.comp\"\n \n-#define BLOCK_SIZE 1024\n+layout(constant_id = 0) const int BLOCK_SIZE = 1024;\n+layout(constant_id = 1) const int BLOCK_SIZE_LOG2 = 10;\n #define ASC 0\n \n-layout(local_size_x = BLOCK_SIZE, local_size_y = 1, local_size_z = 1) in;\n+layout(local_size_x_id = 0, local_size_y = 1, local_size_z = 1) in;\n \n layout (binding = 0) readonly buffer A {A_TYPE data_a[];};\n layout (binding = 1)          buffer D {int data_d[];};\n \n layout (push_constant) uniform parameter {\n     uint ncols;\n-    uint ncols_pad;\n     uint order;\n } p;\n \n shared int dst_row[BLOCK_SIZE];\n+shared A_TYPE a_sh[BLOCK_SIZE];\n \n void swap(uint idx0, uint idx1) {\n     int tmp = dst_row[idx0];\n     dst_row[idx0] = dst_row[idx1];\n     dst_row[idx1] = tmp;\n }\n \n-void main() {\n+void argsort(bool needs_bounds_check) {\n     // bitonic sort\n     const int col = int(gl_LocalInvocationID.x);\n     const uint row = gl_WorkGroupID.y;\n \n     const uint row_offset = row * p.ncols;\n \n     // initialize indices\n-    if (col < p.ncols_pad) {\n-        dst_row[col] = col;\n-    }\n+    dst_row[col] = col;\n+    a_sh[col] = data_a[row_offset + col];\n     barrier();\n \n-    for (uint k = 2; k <= p.ncols_pad; k *= 2) {\n-        for (uint j = k / 2; j > 0; j /= 2) {\n-            const uint ixj = col ^ j;\n-            if (col < p.ncols_pad && ixj > col) {\n-                if ((col & k) == 0) {\n-                    if (dst_row[col] >= p.ncols ||\n-                        (dst_row[ixj] < p.ncols && (p.order == ASC ?\n-                            data_a[row_offset + dst_row[col]] > data_a[row_offset + dst_row[ixj]] :\n-                            data_a[row_offset + dst_row[col]] < data_a[row_offset + dst_row[ixj]]))\n-                    ) {\n-                        swap(col, ixj);\n-                    }\n-                } else {\n-                    if (dst_row[ixj] >= p.ncols ||\n-                        (dst_row[col] < p.ncols && (p.order == ASC ?\n-                            data_a[row_offset + dst_row[col]] < data_a[row_offset + dst_row[ixj]] :\n-                            data_a[row_offset + dst_row[col]] > data_a[row_offset + dst_row[ixj]]))\n-                    ) {\n-                        swap(col, ixj);\n-                    }\n-                }\n+    uint num_outer_loop_iters = BLOCK_SIZE_LOG2;\n+    [[unroll]] for (uint k = 2, outer_idx = 0; outer_idx < num_outer_loop_iters; k *= 2, outer_idx++) {\n+        uint num_inner_loop_iters = outer_idx + 1;\n+        [[unroll]] for (uint j = k / 2, inner_idx = 0; inner_idx < num_inner_loop_iters; j /= 2, inner_idx++) {\n+            const int ixj = int(col ^ j);\n+\n+            int idx_0 = (col & k) == 0 ? col : ixj;\n+            int idx_1 = (col & k) == 0 ? ixj : col;\n+\n+            int sh_idx_0 = dst_row[idx_0];\n+            int sh_idx_1 = dst_row[idx_1];\n+            bool idx_0_oob = needs_bounds_check ? sh_idx_0 >= p.ncols : false;\n+            bool idx_1_oob = needs_bounds_check ? sh_idx_1 >= p.ncols : false;\n+\n+            if ((idx_0_oob ||\n+                (!idx_1_oob && a_sh[sh_idx_0] > a_sh[sh_idx_1])) && (ixj > col)) {\n+                swap(idx_0, idx_1);\n             }\n+\n             barrier();\n         }\n     }\n \n     if (col < p.ncols) {\n-        data_d[row_offset + col] = dst_row[col];\n+        if (p.order == ASC) {\n+            data_d[row_offset + col] = dst_row[col];\n+        } else {\n+            data_d[row_offset + p.ncols - col - 1] = dst_row[col];\n+        }\n+    }\n+}\n+\n+void main() {\n+    if (p.ncols == BLOCK_SIZE) {\n+        argsort(false);\n+    } else {\n+        argsort(true);\n     }\n }",
    "additions": 39,
    "deletions": 29,
    "changes": 68,
    "language": "comp",
    "imports": [],
    "full_content": "#version 450\n#extension GL_EXT_control_flow_attributes : enable\n\n#include \"types.comp\"\n\nlayout(constant_id = 0) const int BLOCK_SIZE = 1024;\nlayout(constant_id = 1) const int BLOCK_SIZE_LOG2 = 10;\n#define ASC 0\n\nlayout(local_size_x_id = 0, local_size_y = 1, local_size_z = 1) in;\n\nlayout (binding = 0) readonly buffer A {A_TYPE data_a[];};\nlayout (binding = 1)          buffer D {int data_d[];};\n\nlayout (push_constant) uniform parameter {\n    uint ncols;\n    uint order;\n} p;\n\nshared int dst_row[BLOCK_SIZE];\nshared A_TYPE a_sh[BLOCK_SIZE];\n\nvoid swap(uint idx0, uint idx1) {\n    int tmp = dst_row[idx0];\n    dst_row[idx0] = dst_row[idx1];\n    dst_row[idx1] = tmp;\n}\n\nvoid argsort(bool needs_bounds_check) {\n    // bitonic sort\n    const int col = int(gl_LocalInvocationID.x);\n    const uint row = gl_WorkGroupID.y;\n\n    const uint row_offset = row * p.ncols;\n\n    // initialize indices\n    dst_row[col] = col;\n    a_sh[col] = data_a[row_offset + col];\n    barrier();\n\n    uint num_outer_loop_iters = BLOCK_SIZE_LOG2;\n    [[unroll]] for (uint k = 2, outer_idx = 0; outer_idx < num_outer_loop_iters; k *= 2, outer_idx++) {\n        uint num_inner_loop_iters = outer_idx + 1;\n        [[unroll]] for (uint j = k / 2, inner_idx = 0; inner_idx < num_inner_loop_iters; j /= 2, inner_idx++) {\n            const int ixj = int(col ^ j);\n\n            int idx_0 = (col & k) == 0 ? col : ixj;\n            int idx_1 = (col & k) == 0 ? ixj : col;\n\n            int sh_idx_0 = dst_row[idx_0];\n            int sh_idx_1 = dst_row[idx_1];\n            bool idx_0_oob = needs_bounds_check ? sh_idx_0 >= p.ncols : false;\n            bool idx_1_oob = needs_bounds_check ? sh_idx_1 >= p.ncols : false;\n\n            if ((idx_0_oob ||\n                (!idx_1_oob && a_sh[sh_idx_0] > a_sh[sh_idx_1])) && (ixj > col)) {\n                swap(idx_0, idx_1);\n            }\n\n            barrier();\n        }\n    }\n\n    if (col < p.ncols) {\n        if (p.order == ASC) {\n            data_d[row_offset + col] = dst_row[col];\n        }",
    "raw_url": "https://github.com/ggml-org/llama.cpp/raw/c9e4504a780b32c13a9c0fad51164bc0c27cb8c1/ggml%2Fsrc%2Fggml-vulkan%2Fvulkan-shaders%2Fargsort.comp",
    "is_test_file": false
  },
  "tests/test-backend-ops.cpp": {
    "status": "modified",
    "patch": "@@ -6024,6 +6024,7 @@ static std::vector<std::unique_ptr<test_case>> make_test_cases_eval() {\n         test_cases.emplace_back(new test_argsort(GGML_TYPE_F32, {8, 1, 1, 1}, order));\n         test_cases.emplace_back(new test_argsort(GGML_TYPE_F32, {16, 10, 10, 10}, order));\n         test_cases.emplace_back(new test_argsort(GGML_TYPE_F32, {60, 10, 10, 10}, order)); // qwen\n+        test_cases.emplace_back(new test_argsort(GGML_TYPE_F32, {1024, 1, 1, 1}, order));\n     }\n \n     for (ggml_scale_mode mode : {GGML_SCALE_MODE_NEAREST, GGML_SCALE_MODE_BILINEAR}) {",
    "additions": 1,
    "deletions": 0,
    "changes": 1,
    "language": "cpp",
    "imports": [
      "#include <ggml.h>",
      "#include <ggml-alloc.h>",
      "#include <ggml-backend.h>",
      "#include <ggml-cpp.h>",
      "#include <algorithm>",
      "#include <array>",
      "#include <cfloat>",
      "#include <cinttypes>",
      "#include <cstdarg>",
      "#include <cstdint>"
    ],
    "full_content": "// This file defines tests for various GGML ops and backends.\n// For the forward pass it asserts that the results of multiple backends computing the same GGML ops are consistent.\n// For the backward pass it asserts that the gradients from backpropagation are consistent\n// with the gradients obtained via the method of finite differences (\"grad\" mode, this is optional).\n// It is also possible to check the performance (\"perf\" mode).\n//\n// this file has three sections: Section 1 does general setup, section 2 defines the GGML ops to be tested,\n// and section 3 defines which tests to run.\n// Quick start for adding a new GGML op: Go to section 2 and create a struct that inherits from test_case,\n// then go to section 3 and add an instantiation of your struct.\n\n\n// ##############################\n// ## Section 1: General Setup ##\n// ##############################\n\n\n#include <ggml.h>\n#include <ggml-alloc.h>\n#include <ggml-backend.h>\n#include <ggml-cpp.h>\n\n#include <algorithm>\n#include <array>\n#include <cfloat>\n#include <cinttypes>\n#include <cstdarg>\n#include <cstdint>\n#include <cstdio>\n#include <cstdlib>\n#include <cstring>\n#include <ctime>\n#include <future>\n#include <memory>\n#include <random>\n#include <regex>\n#include <string>\n#include <string_view>\n#include <thread>\n#include <vector>\n\nstatic void init_tensor_uniform(ggml_tensor * tensor, float min = -1.0f, float max = 1.0f) {\n    size_t nels = ggml_nelements(tensor);\n    std::vector<float> data(nels);\n    {\n        // parallel initialization\n        static const size_t n_threads = std::thread::hardware_concurrency();\n        // static RNG initialization (revisit if n_threads stops being constant)\n        static std::vector<std::default_random_engine> generators = []() {\n            std::random_device rd;\n            std::vector<std::default_random_engine> vec;\n            vec.reserve(n_threads);\n            //for (size_t i = 0; i < n_threads; i++) { vec.emplace_back(1234 + i); } // fixed seed\n            for (size_t i = 0; i ",
    "raw_url": "https://github.com/ggml-org/llama.cpp/raw/c9e4504a780b32c13a9c0fad51164bc0c27cb8c1/tests%2Ftest-backend-ops.cpp",
    "is_test_file": true
  }
}